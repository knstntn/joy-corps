## 1. Extend and merge data ---3 days 
According to the time information: 
1. extend data: if a certain period of information loss, fill it with the previous data.
2. merge data: integrate all the features. if miss some features fill it with 0.
## 2. Multi-class logistic with neural network ---2 days, score: 20%
express each sample as a vector, using softmax function for prediction.
## 3. Multi-layer percetron ---1 day score: 25%
with the Multi-class logistic different, there are two layers of hidden layers added to the input and output layers.
## 4. Xgboost ---2 days, score: 35%
I tried to change some parameters, such as: Eta, Gamma, Max_depth, Lambda and alpha.
## 5. Logistic regression with sklearn ---2 days, score: 46%
Only two parameters: penalty='l2', C=10.
## 6. Long short term memory ---15 days, score: 51%
It's a little surprising at 15 days, because it includes my time on learning pytorch to build Bi-LSTM.
During this time, I tried some ideas to deal with the dataset and looked for the better parameters.
